{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_segment(input_file, start_time, end_time, output_file):\n",
    "    \"\"\"\n",
    "    Extracts a segment from an audio file based on start and end timestamps.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input audio file.\n",
    "        start_time (int): Start time in milliseconds.\n",
    "        end_time (int): End time in milliseconds.\n",
    "        output_file (str): Path to the output audio file.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_wav(input_file) # Load the audio file\n",
    "    segment = audio[start_time:end_time] # Extract the segment\n",
    "    segment.export(output_file, format=\"wav\") # Export the segment as a new WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment participant's conversation audio files\n",
    "for i in range():\n",
    "    number = str(i).zfill(2)\n",
    "    input_file = f'updated_annotation_deid_full/00{number}/D00{number}_A.txt'\n",
    "    df = pd.read_csv(input_file, sep='\\t', names=['Starting', 'Ending', 'Transcript'])\n",
    "    input_audio = f'audio_deid_full/00{number}/meeting_01.wav'\n",
    "    for j in range(df.shape[0]):\n",
    "        start_time = df['Starting'][j] * 1000\n",
    "        end_time = df['Ending'][j] * 1000\n",
    "        output_file = f'conversation{input_file[6]}-{input_file[1:5]}_{start_time/1000}_{end_time/1000}.wav'\n",
    "        extract_audio_segment(input_audio, start_time, end_time, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment moderator's conversation audio files\n",
    "for i in range():\n",
    "  number = str(i).zfill(2)\n",
    "  input_file = f'updated_annotation_deid_full/00{number}/D00{number}_B.txt'\n",
    "  df = pd.read_csv(input_file, sep='\\t', names=['Starting', 'Ending', 'Transcript'])\n",
    "  input_audio = f'audio_deid_full/00{number}/meeting_01.wav'\n",
    "  for j in range(df.shape[0]):\n",
    "    start_time = df['Starting'][j] * 1000\n",
    "    end_time = df['Ending'][j] * 1000\n",
    "    output_file = f'conversation{input_file[6]}-{input_file[1:5]}_{start_time/1000}_{end_time/1000}.wav'\n",
    "    extract_audio_segment(input_audio, start_time, end_time, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment voice command audio files\n",
    "for i in range():\n",
    "  number = str(i).zfill(2)\n",
    "  input_file = f'updated_annotation_deid_full/00{number}/P00{number}.txt'\n",
    "  df = pd.read_csv(input_file, sep='\\t', names=['Starting', 'Ending', 'Transcript'])\n",
    "  input_audio = f'audio_deid_full/00{number}/meeting_01.wav'\n",
    "  for j in range(df.shape[0]):\n",
    "    start_time = df['Starting'][j] * 1000\n",
    "    end_time = df['Ending'][j] * 1000\n",
    "    output_file = f'conversation{input_file[6]}-{input_file[1:5]}_{start_time/1000}_{end_time/1000}.wav'\n",
    "    extract_audio_segment(input_audio, start_time, end_time, output_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
